<!DOCTYPE html>
<meta charset="utf-8">
<body>
<script src="https://d3js.org/d3.v4.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@hpcc-js/wasm/dist/graphviz.umd.js" type="javascript/worker"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/d3-graphviz/5.0.2/d3-graphviz.min.js"></script>
<div id="graph" style="text-align: center;"></div>

<!--
    Template from the d3-graphviz examples:
    https://github.com/magjac/d3-graphviz/blob/master/examples/demo.html
-->

<script>

var dotIndex = 0;
var graphviz = d3.select("#graph").graphviz()
    .transition(function () {
        return d3.transition("main")
            .ease(d3.easeLinear)
            //.delay(500)
            .duration(2000);
    })
    .logEvents(true)
    .on("initEnd", render);

function render() {
    var dot = dots[dotIndex];
    graphviz
        .renderDot(dot)
        .on("end", function () {
            dotIndex = (dotIndex + 1) % dots.length;            
            render();
        });
}

var dots = [
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }

  # NOTE: this \line on\ly used in ear\ly versions of the diagram
  # \later we \link to the c\luster, not the node 
 {mode\l comparison_thing} -> compare;


}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }

  # NOTE: this \line on\ly used in ear\ly versions of the diagram
  # \later we \link to the c\luster, not the node 
 {mode\l comparison_thing} -> compare;



  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }

  # NOTE: this \line on\ly used in ear\ly versions of the diagram
  # \later we \link to the c\luster, not the node 
 {mode\l comparison_thing} -> compare;



  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }

  # NOTE: this \line on\ly used in ear\ly versions of the diagram
  # \later we \link to the c\luster, not the node 
 {mode\l comparison_thing} -> compare;



  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }

  # NOTE: this \line on\ly used in ear\ly versions of the diagram
  # \later we \link to the c\luster, not the node 
 {mode\l comparison_thing} -> compare;



  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

  /*
Negative Confirmation is often ca\l\led a 'Test Fai\l'.

This means we observed something we did not expect.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    positive_confirmation;
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=1 height=0];
    negative_confirmation;
  }

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }

  # NOTE: this \line on\ly used in ear\ly versions of the diagram
  # \later we \link to the c\luster, not the node 
 {mode\l comparison_thing} -> compare;



  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

  /*
Negative Confirmation is often ca\l\led a 'Test Fai\l'.

This means we observed something we did not expect.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    positive_confirmation;
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=1 height=0];
    negative_confirmation;
  }

  negative_confirmation [
    \labe\l ="Negative\n Confirmation",
    fi\l\lco\lor=red,
    sty\le=fi\l\led
  ]

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }

  # NOTE: this \line on\ly used in ear\ly versions of the diagram
  # \later we \link to the c\luster, not the node 
 {mode\l comparison_thing} -> compare;



  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

  /*
Negative Confirmation is often ca\l\led a 'Test Fai\l'.

This means we observed something we did not expect.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    positive_confirmation;
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=1 height=0];
    negative_confirmation;
  }

  negative_confirmation [
    \labe\l ="Negative\n Confirmation",
    fi\l\lco\lor=red,
    sty\le=fi\l\led
  ]


  /*
These positive and negative reports are a visib\le output
from the Testing process.
  */


  /*
So we have to investigate what fai\led during our comparison process.
  */

  negative_confirmation -> investigation;
  investigation [
    \labe\l="Investigate",
    shape=square
  ]

  /*
This might mean:

- a prob\lem with our mode\l
- a prob\lem with the System Under Test
- a prob\lem with our comparison process

Either way it is something we have to investigate.
  */

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }

  # NOTE: this \line on\ly used in ear\ly versions of the diagram
  # \later we \link to the c\luster, not the node 
 {mode\l comparison_thing} -> compare;



  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

  /*
Negative Confirmation is often ca\l\led a 'Test Fai\l'.

This means we observed something we did not expect.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    positive_confirmation;
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=1 height=0];
    negative_confirmation;
  }

  negative_confirmation [
    \labe\l ="Negative\n Confirmation",
    fi\l\lco\lor=red,
    sty\le=fi\l\led
  ]


  /*
These positive and negative reports are a visib\le output
from the Testing process.
  */


  /*
So we have to investigate what fai\led during our comparison process.
  */

  negative_confirmation -> investigation;
  investigation [
    \labe\l="Investigate",
    shape=square
  ]

  /*
This might mean:

- a prob\lem with our mode\l
- a prob\lem with the System Under Test
- a prob\lem with our comparison process

Either way it is something we have to investigate.
  */

  investigation -> mode\l [
    \labe\l="- Mode\l does not \\l  match rea\lity \\l- Change the mode\l.\\l"
  ];

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }

  # NOTE: this \line on\ly used in ear\ly versions of the diagram
  # \later we \link to the c\luster, not the node 
 {mode\l comparison_thing} -> compare;



  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

  /*
Negative Confirmation is often ca\l\led a 'Test Fai\l'.

This means we observed something we did not expect.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    positive_confirmation;
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=1 height=0];
    negative_confirmation;
  }

  negative_confirmation [
    \labe\l ="Negative\n Confirmation",
    fi\l\lco\lor=red,
    sty\le=fi\l\led
  ]


  /*
These positive and negative reports are a visib\le output
from the Testing process.
  */


  /*
So we have to investigate what fai\led during our comparison process.
  */

  negative_confirmation -> investigation;
  investigation [
    \labe\l="Investigate",
    shape=square
  ]

  /*
This might mean:

- a prob\lem with our mode\l
- a prob\lem with the System Under Test
- a prob\lem with our comparison process

Either way it is something we have to investigate.
  */

  investigation -> mode\l [
    \labe\l="- Mode\l does not \\l  match rea\lity \\l- Change the mode\l.\\l"
  ];

  investigation -> compare [
    \labe\l="- Process Issue.\\l- We did not use\\l  the system proper\ly.\\l- Re-eva\luate.\\l"
    \lhead=c\luster_eva\luation
  ];

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }

  # NOTE: this \line on\ly used in ear\ly versions of the diagram
  # \later we \link to the c\luster, not the node 
 {mode\l comparison_thing} -> compare;



  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

  /*
Negative Confirmation is often ca\l\led a 'Test Fai\l'.

This means we observed something we did not expect.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    positive_confirmation;
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=1 height=0];
    negative_confirmation;
  }

  negative_confirmation [
    \labe\l ="Negative\n Confirmation",
    fi\l\lco\lor=red,
    sty\le=fi\l\led
  ]


  /*
These positive and negative reports are a visib\le output
from the Testing process.
  */


  /*
So we have to investigate what fai\led during our comparison process.
  */

  negative_confirmation -> investigation;
  investigation [
    \labe\l="Investigate",
    shape=square
  ]

  /*
This might mean:

- a prob\lem with our mode\l
- a prob\lem with the System Under Test
- a prob\lem with our comparison process

Either way it is something we have to investigate.
  */

  investigation -> mode\l [
    \labe\l="- Mode\l does not \\l  match rea\lity \\l- Change the mode\l.\\l"
  ];

  investigation -> compare [
    \labe\l="- Process Issue.\\l- We did not use\\l  the system proper\ly.\\l- Re-eva\luate.\\l"
    \lhead=c\luster_eva\luation
  ];

   investigation -> comparison_thing [
     \labe\l="System does not match\n what we require.\n Found a Bug.\n Fix the System."
   ];

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }

  # NOTE: this \line on\ly used in ear\ly versions of the diagram
  # \later we \link to the c\luster, not the node 
 {mode\l comparison_thing} -> compare;



  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

  /*
Negative Confirmation is often ca\l\led a 'Test Fai\l'.

This means we observed something we did not expect.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    positive_confirmation;
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=1 height=0];
    negative_confirmation;
  }

  negative_confirmation [
    \labe\l ="Negative\n Confirmation",
    fi\l\lco\lor=red,
    sty\le=fi\l\led
  ]


  /*
These positive and negative reports are a visib\le output
from the Testing process.
  */


  /*
So we have to investigate what fai\led during our comparison process.
  */

  negative_confirmation -> investigation;
  investigation [
    \labe\l="Investigate",
    shape=square
  ]

  /*
This might mean:

- a prob\lem with our mode\l
- a prob\lem with the System Under Test
- a prob\lem with our comparison process

Either way it is something we have to investigate.
  */

  investigation -> mode\l [
    \labe\l="- Mode\l does not \\l  match rea\lity \\l- Change the mode\l.\\l"
  ];

  investigation -> compare [
    \labe\l="- Process Issue.\\l- We did not use\\l  the system proper\ly.\\l- Re-eva\luate.\\l"
    \lhead=c\luster_eva\luation
  ];

  investigation -> raise_bug [
    \labe\l="- System does not match\n what we require."
  ];
  raise_bug [\labe\l="Raise Bug"];
  raise_bug -> fix_bug;
  fix_bug [\labe\l="Fix Bug"];
  fix_bug -> comparison_thing [\labe\l="- Fix the System"];


  subgraph c\luster_investigate {
    investigation;

        subgraph c\luster_defect_process {
          rank=same
          node [rankdir=LR]
          raise_bug;
          fix_bug;
        }
  }

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }

  # NOTE: this \line on\ly used in ear\ly versions of the diagram
  # \later we \link to the c\luster, not the node 
 {mode\l comparison_thing} -> compare;



  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

  /*
Negative Confirmation is often ca\l\led a 'Test Fai\l'.

This means we observed something we did not expect.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    positive_confirmation;
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=1 height=0];
    negative_confirmation;
  }

  negative_confirmation [
    \labe\l ="Negative\n Confirmation",
    fi\l\lco\lor=red,
    sty\le=fi\l\led
  ]


  /*
These positive and negative reports are a visib\le output
from the Testing process.
  */


  /*
So we have to investigate what fai\led during our comparison process.
  */

  negative_confirmation -> investigation;
  investigation [
    \labe\l="Investigate",
    shape=square
  ]

  /*
This might mean:

- a prob\lem with our mode\l
- a prob\lem with the System Under Test
- a prob\lem with our comparison process

Either way it is something we have to investigate.
  */

  investigation -> mode\l [
    \labe\l="- Mode\l does not \\l  match rea\lity \\l- Change the mode\l.\\l"
  ];

  investigation -> compare [
    \labe\l="- Process Issue.\\l- We did not use\\l  the system proper\ly.\\l- Re-eva\luate.\\l"
    \lhead=c\luster_eva\luation
  ];

  investigation -> raise_bug [
    \labe\l="- System does not match\n what we require."
  ];
  raise_bug [\labe\l="Raise Bug"];
  raise_bug -> fix_bug;
  fix_bug [\labe\l="Fix Bug"];
  fix_bug -> comparison_thing [\labe\l="- Fix the System"];


  subgraph c\luster_investigate {
    investigation;

        subgraph c\luster_defect_process {
          rank=same
          node [rankdir=LR]
          raise_bug;
          fix_bug;
        }
  }

  /*
A comparison process from mode\l to 'thing' isn't the on\ly process that
Software Testing invo\lves, it's just one of the most obvious ways we have
of eva\luating the Software.

And Software Testing is a process of eva\luating the software.

  */
  compare [sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  subgraph c\luster_eva\luation {
      \labe\l="Eva\luation";
      compare;
  }

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }

  # NOTE: this \line on\ly used in ear\ly versions of the diagram
  # \later we \link to the c\luster, not the node 
 {mode\l comparison_thing} -> compare;



  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

  /*
Negative Confirmation is often ca\l\led a 'Test Fai\l'.

This means we observed something we did not expect.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    positive_confirmation;
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=1 height=0];
    negative_confirmation;
  }

  negative_confirmation [
    \labe\l ="Negative\n Confirmation",
    fi\l\lco\lor=red,
    sty\le=fi\l\led
  ]


  /*
These positive and negative reports are a visib\le output
from the Testing process.
  */


  /*
So we have to investigate what fai\led during our comparison process.
  */

  negative_confirmation -> investigation;
  investigation [
    \labe\l="Investigate",
    shape=square
  ]

  /*
This might mean:

- a prob\lem with our mode\l
- a prob\lem with the System Under Test
- a prob\lem with our comparison process

Either way it is something we have to investigate.
  */

  investigation -> mode\l [
    \labe\l="- Mode\l does not \\l  match rea\lity \\l- Change the mode\l.\\l"
  ];

  investigation -> compare [
    \labe\l="- Process Issue.\\l- We did not use\\l  the system proper\ly.\\l- Re-eva\luate.\\l"
    \lhead=c\luster_eva\luation
  ];

  investigation -> raise_bug [
    \labe\l="- System does not match\n what we require."
  ];
  raise_bug [\labe\l="Raise Bug"];
  raise_bug -> fix_bug;
  fix_bug [\labe\l="Fix Bug"];
  fix_bug -> comparison_thing [\labe\l="- Fix the System"];


  subgraph c\luster_investigate {
    investigation;

        subgraph c\luster_defect_process {
          rank=same
          node [rankdir=LR]
          raise_bug;
          fix_bug;
        }
  }

  /*
A comparison process from mode\l to 'thing' isn't the on\ly process that
Software Testing invo\lves, it's just one of the most obvious ways we have
of eva\luating the Software.

And Software Testing is a process of eva\luating the software.

  */
  compare [sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  subgraph c\luster_eva\luation {
      \labe\l="Eva\luation";
      compare;
  }

  /*

We can direct\ly compare Requirements with the Software for high \leve\l surface
positive or negative confirmation that a requirement has been imp\lemented.

e.g. "A User must be ab\le to \login with their username and password." can be
confirmed quite simp\ly by \logging in with an existing user and their correct
password.

But during the Software Testing process we a\lso try to expand our mode\l beyond
Requirements.

We a\lso exp\lore our mode\l in conjunction with the system to \learn more about
our mode\l and as a consequence, the system itse\lf.
  
  */

  compare [sty\le=fi\l\led, fi\l\lco\lor=white];
  subgraph c\luster_eva\luation {
      rank=same
      node [rankdir=LR]
      \labe\l="Eva\luation";
      compare;
      mode\l\ling;
      exp\loration;
  }

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }

  # NOTE: this \line on\ly used in ear\ly versions of the diagram
  # \later we \link to the c\luster, not the node 
 {mode\l comparison_thing} -> compare;



  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

  /*
Negative Confirmation is often ca\l\led a 'Test Fai\l'.

This means we observed something we did not expect.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    positive_confirmation;
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=1 height=0];
    negative_confirmation;
  }

  negative_confirmation [
    \labe\l ="Negative\n Confirmation",
    fi\l\lco\lor=red,
    sty\le=fi\l\led
  ]


  /*
These positive and negative reports are a visib\le output
from the Testing process.
  */


  /*
So we have to investigate what fai\led during our comparison process.
  */

  negative_confirmation -> investigation;
  investigation [
    \labe\l="Investigate",
    shape=square
  ]

  /*
This might mean:

- a prob\lem with our mode\l
- a prob\lem with the System Under Test
- a prob\lem with our comparison process

Either way it is something we have to investigate.
  */

  investigation -> mode\l [
    \labe\l="- Mode\l does not \\l  match rea\lity \\l- Change the mode\l.\\l"
  ];

  investigation -> compare [
    \labe\l="- Process Issue.\\l- We did not use\\l  the system proper\ly.\\l- Re-eva\luate.\\l"
    \lhead=c\luster_eva\luation
  ];

  investigation -> raise_bug [
    \labe\l="- System does not match\n what we require."
  ];
  raise_bug [\labe\l="Raise Bug"];
  raise_bug -> fix_bug;
  fix_bug [\labe\l="Fix Bug"];
  fix_bug -> comparison_thing [\labe\l="- Fix the System"];


  subgraph c\luster_investigate {
    investigation;

        subgraph c\luster_defect_process {
          rank=same
          node [rankdir=LR]
          raise_bug;
          fix_bug;
        }
  }

  /*
A comparison process from mode\l to 'thing' isn't the on\ly process that
Software Testing invo\lves, it's just one of the most obvious ways we have
of eva\luating the Software.

And Software Testing is a process of eva\luating the software.

  */
  compare [sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  subgraph c\luster_eva\luation {
      \labe\l="Eva\luation";
      compare;
  }

  /*

We can direct\ly compare Requirements with the Software for high \leve\l surface
positive or negative confirmation that a requirement has been imp\lemented.

e.g. "A User must be ab\le to \login with their username and password." can be
confirmed quite simp\ly by \logging in with an existing user and their correct
password.

But during the Software Testing process we a\lso try to expand our mode\l beyond
Requirements.

We a\lso exp\lore our mode\l in conjunction with the system to \learn more about
our mode\l and as a consequence, the system itse\lf.
  
  */

  compare [sty\le=fi\l\led, fi\l\lco\lor=white];
  subgraph c\luster_eva\luation {
      rank=same
      node [rankdir=LR]
      \labe\l="Eva\luation";
      compare;
      mode\l\ling;
      exp\loration;
  }

  /*

Software Testing has to exp\lore our mode\l to identify:

- risks
- ambiguity
- gaps in the mode\ls and imp\lementation
- etc.

This raises questions which we have to investigate and discuss.

The ongoing process of mode\l\ling is how we generate our ideas
for testing and how we find new ways to exp\lore the software.

  */


  mode\l\ling [\labe\l="Mode\ling", shape=square, sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  mode\l\ling -> mode\l [
    \labe\l="Expand Mode\l:\\l\\l- risks\\l- ambiguity\\l- gaps\\l- questions\\l - etc.\\l"
    \ltai\l=c\luster_eva\luation;
  ];

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }

  # NOTE: this \line on\ly used in ear\ly versions of the diagram
  # \later we \link to the c\luster, not the node 
 {mode\l comparison_thing} -> compare;



  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

  /*
Negative Confirmation is often ca\l\led a 'Test Fai\l'.

This means we observed something we did not expect.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    positive_confirmation;
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=1 height=0];
    negative_confirmation;
  }

  negative_confirmation [
    \labe\l ="Negative\n Confirmation",
    fi\l\lco\lor=red,
    sty\le=fi\l\led
  ]


  /*
These positive and negative reports are a visib\le output
from the Testing process.
  */


  /*
So we have to investigate what fai\led during our comparison process.
  */

  negative_confirmation -> investigation;
  investigation [
    \labe\l="Investigate",
    shape=square
  ]

  /*
This might mean:

- a prob\lem with our mode\l
- a prob\lem with the System Under Test
- a prob\lem with our comparison process

Either way it is something we have to investigate.
  */

  investigation -> mode\l [
    \labe\l="- Mode\l does not \\l  match rea\lity \\l- Change the mode\l.\\l"
  ];

  investigation -> compare [
    \labe\l="- Process Issue.\\l- We did not use\\l  the system proper\ly.\\l- Re-eva\luate.\\l"
    \lhead=c\luster_eva\luation
  ];

  investigation -> raise_bug [
    \labe\l="- System does not match\n what we require."
  ];
  raise_bug [\labe\l="Raise Bug"];
  raise_bug -> fix_bug;
  fix_bug [\labe\l="Fix Bug"];
  fix_bug -> comparison_thing [\labe\l="- Fix the System"];


  subgraph c\luster_investigate {
    investigation;

        subgraph c\luster_defect_process {
          rank=same
          node [rankdir=LR]
          raise_bug;
          fix_bug;
        }
  }

  /*
A comparison process from mode\l to 'thing' isn't the on\ly process that
Software Testing invo\lves, it's just one of the most obvious ways we have
of eva\luating the Software.

And Software Testing is a process of eva\luating the software.

  */
  compare [sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  subgraph c\luster_eva\luation {
      \labe\l="Eva\luation";
      compare;
  }

  /*

We can direct\ly compare Requirements with the Software for high \leve\l surface
positive or negative confirmation that a requirement has been imp\lemented.

e.g. "A User must be ab\le to \login with their username and password." can be
confirmed quite simp\ly by \logging in with an existing user and their correct
password.

But during the Software Testing process we a\lso try to expand our mode\l beyond
Requirements.

We a\lso exp\lore our mode\l in conjunction with the system to \learn more about
our mode\l and as a consequence, the system itse\lf.
  
  */

  compare [sty\le=fi\l\led, fi\l\lco\lor=white];
  subgraph c\luster_eva\luation {
      rank=same
      node [rankdir=LR]
      \labe\l="Eva\luation";
      compare;
      mode\l\ling;
      exp\loration;
  }

  /*

Software Testing has to exp\lore our mode\l to identify:

- risks
- ambiguity
- gaps in the mode\ls and imp\lementation
- etc.

This raises questions which we have to investigate and discuss.

The ongoing process of mode\l\ling is how we generate our ideas
for testing and how we find new ways to exp\lore the software.

  */


  mode\l\ling [\labe\l="Mode\ling", shape=square, sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  mode\l\ling -> mode\l [
    \labe\l="Expand Mode\l:\\l\\l- risks\\l- ambiguity\\l- gaps\\l- questions\\l - etc.\\l"
    \ltai\l=c\luster_eva\luation;
  ];

  /*
The mode\l is both an input to testing, and an output from Testing.

Parts of the mode\l wi\l\l be stored in the Tester's head as a menta\l mode\l.

Other parts wi\l\l be visib\le in the form of diagrams, reports,
\lists of test ideas, etc.
  */
  mode\l [\labe\l="Mode\l" sty\le=fi\l\led fi\l\lco\lor=ye\l\low];

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }

  # NOTE: this \line on\ly used in ear\ly versions of the diagram
  # \later we \link to the c\luster, not the node 
 {mode\l comparison_thing} -> compare;



  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

  /*
Negative Confirmation is often ca\l\led a 'Test Fai\l'.

This means we observed something we did not expect.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    positive_confirmation;
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=1 height=0];
    negative_confirmation;
  }

  negative_confirmation [
    \labe\l ="Negative\n Confirmation",
    fi\l\lco\lor=red,
    sty\le=fi\l\led
  ]


  /*
These positive and negative reports are a visib\le output
from the Testing process.
  */


  /*
So we have to investigate what fai\led during our comparison process.
  */

  negative_confirmation -> investigation;
  investigation [
    \labe\l="Investigate",
    shape=square
  ]

  /*
This might mean:

- a prob\lem with our mode\l
- a prob\lem with the System Under Test
- a prob\lem with our comparison process

Either way it is something we have to investigate.
  */

  investigation -> mode\l [
    \labe\l="- Mode\l does not \\l  match rea\lity \\l- Change the mode\l.\\l"
  ];

  investigation -> compare [
    \labe\l="- Process Issue.\\l- We did not use\\l  the system proper\ly.\\l- Re-eva\luate.\\l"
    \lhead=c\luster_eva\luation
  ];

  investigation -> raise_bug [
    \labe\l="- System does not match\n what we require."
  ];
  raise_bug [\labe\l="Raise Bug"];
  raise_bug -> fix_bug;
  fix_bug [\labe\l="Fix Bug"];
  fix_bug -> comparison_thing [\labe\l="- Fix the System"];


  subgraph c\luster_investigate {
    investigation;

        subgraph c\luster_defect_process {
          rank=same
          node [rankdir=LR]
          raise_bug;
          fix_bug;
        }
  }

  /*
A comparison process from mode\l to 'thing' isn't the on\ly process that
Software Testing invo\lves, it's just one of the most obvious ways we have
of eva\luating the Software.

And Software Testing is a process of eva\luating the software.

  */
  compare [sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  subgraph c\luster_eva\luation {
      \labe\l="Eva\luation";
      compare;
  }

  /*

We can direct\ly compare Requirements with the Software for high \leve\l surface
positive or negative confirmation that a requirement has been imp\lemented.

e.g. "A User must be ab\le to \login with their username and password." can be
confirmed quite simp\ly by \logging in with an existing user and their correct
password.

But during the Software Testing process we a\lso try to expand our mode\l beyond
Requirements.

We a\lso exp\lore our mode\l in conjunction with the system to \learn more about
our mode\l and as a consequence, the system itse\lf.
  
  */

  compare [sty\le=fi\l\led, fi\l\lco\lor=white];
  subgraph c\luster_eva\luation {
      rank=same
      node [rankdir=LR]
      \labe\l="Eva\luation";
      compare;
      mode\l\ling;
      exp\loration;
  }

  /*

Software Testing has to exp\lore our mode\l to identify:

- risks
- ambiguity
- gaps in the mode\ls and imp\lementation
- etc.

This raises questions which we have to investigate and discuss.

The ongoing process of mode\l\ling is how we generate our ideas
for testing and how we find new ways to exp\lore the software.

  */


  mode\l\ling [\labe\l="Mode\ling", shape=square, sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  mode\l\ling -> mode\l [
    \labe\l="Expand Mode\l:\\l\\l- risks\\l- ambiguity\\l- gaps\\l- questions\\l - etc.\\l"
    \ltai\l=c\luster_eva\luation;
  ];

  /*
The mode\l is both an input to testing, and an output from Testing.

Parts of the mode\l wi\l\l be stored in the Tester's head as a menta\l mode\l.

Other parts wi\l\l be visib\le in the form of diagrams, reports,
\lists of test ideas, etc.
  */
  mode\l [\labe\l="Mode\l" sty\le=fi\l\led fi\l\lco\lor=ye\l\low];

  /*

Software Testing then has to exp\lore the mode\l in conjunction
with the system to identify if any of these manifest as issues
or potentia\l\ly require reworking the imp\lementation.

  */

  mode\l\ling [\labe\l="Mode\ling", shape=square, sty\le=fi\l\led, fi\l\lco\lor=white];
  exp\loration [\labe\l="Exp\loring", shape=square, sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }


  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

  /*
Negative Confirmation is often ca\l\led a 'Test Fai\l'.

This means we observed something we did not expect.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    positive_confirmation;
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=1 height=0];
    negative_confirmation;
  }

  negative_confirmation [
    \labe\l ="Negative\n Confirmation",
    fi\l\lco\lor=red,
    sty\le=fi\l\led
  ]


  /*
These positive and negative reports are a visib\le output
from the Testing process.
  */


  /*
So we have to investigate what fai\led during our comparison process.
  */

  negative_confirmation -> investigation;
  investigation [
    \labe\l="Investigate",
    shape=square
  ]

  /*
This might mean:

- a prob\lem with our mode\l
- a prob\lem with the System Under Test
- a prob\lem with our comparison process

Either way it is something we have to investigate.
  */

  investigation -> mode\l [
    \labe\l="- Mode\l does not \\l  match rea\lity \\l- Change the mode\l.\\l"
  ];

  investigation -> compare [
    \labe\l="- Process Issue.\\l- We did not use\\l  the system proper\ly.\\l- Re-eva\luate.\\l"
    \lhead=c\luster_eva\luation
  ];

  investigation -> raise_bug [
    \labe\l="- System does not match\n what we require."
  ];
  raise_bug [\labe\l="Raise Bug"];
  raise_bug -> fix_bug;
  fix_bug [\labe\l="Fix Bug"];
  fix_bug -> comparison_thing [\labe\l="- Fix the System"];


  subgraph c\luster_investigate {
    investigation;

        subgraph c\luster_defect_process {
          rank=same
          node [rankdir=LR]
          raise_bug;
          fix_bug;
        }
  }

  /*
A comparison process from mode\l to 'thing' isn't the on\ly process that
Software Testing invo\lves, it's just one of the most obvious ways we have
of eva\luating the Software.

And Software Testing is a process of eva\luating the software.

  */
  compare [sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  subgraph c\luster_eva\luation {
      \labe\l="Eva\luation";
      compare;
  }

  /*

We can direct\ly compare Requirements with the Software for high \leve\l surface
positive or negative confirmation that a requirement has been imp\lemented.

e.g. "A User must be ab\le to \login with their username and password." can be
confirmed quite simp\ly by \logging in with an existing user and their correct
password.

But during the Software Testing process we a\lso try to expand our mode\l beyond
Requirements.

We a\lso exp\lore our mode\l in conjunction with the system to \learn more about
our mode\l and as a consequence, the system itse\lf.
  
  */

  compare [sty\le=fi\l\led, fi\l\lco\lor=white];
  subgraph c\luster_eva\luation {
      rank=same
      node [rankdir=LR]
      \labe\l="Eva\luation";
      compare;
      mode\l\ling;
      exp\loration;
  }

  /*

Software Testing has to exp\lore our mode\l to identify:

- risks
- ambiguity
- gaps in the mode\ls and imp\lementation
- etc.

This raises questions which we have to investigate and discuss.

The ongoing process of mode\l\ling is how we generate our ideas
for testing and how we find new ways to exp\lore the software.

  */


  mode\l\ling [\labe\l="Mode\ling", shape=square, sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  mode\l\ling -> mode\l [
    \labe\l="Expand Mode\l:\\l\\l- risks\\l- ambiguity\\l- gaps\\l- questions\\l - etc.\\l"
    \ltai\l=c\luster_eva\luation;
  ];

  /*
The mode\l is both an input to testing, and an output from Testing.

Parts of the mode\l wi\l\l be stored in the Tester's head as a menta\l mode\l.

Other parts wi\l\l be visib\le in the form of diagrams, reports,
\lists of test ideas, etc.
  */
  mode\l [\labe\l="Mode\l" sty\le=fi\l\led fi\l\lco\lor=ye\l\low];

  /*

Software Testing then has to exp\lore the mode\l in conjunction
with the system to identify if any of these manifest as issues
or potentia\l\ly require reworking the imp\lementation.

  */

  mode\l\ling [\labe\l="Mode\ling", shape=square, sty\le=fi\l\led, fi\l\lco\lor=white];
  exp\loration [\labe\l="Exp\loring", shape=square, sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];

  {mode\l comparison_thing} -> compare [\lhead=c\luster_eva\luation];


    /*
One examp\le of ambiguity arises from requirements being natura\l\ly incomp\lete because
of assumptions in understanding.

The requirement for \logging into the system does not describe:

- what happens if the user is a\lready \logged in?
- what message is disp\layed if the user gets the password wrong?
- what message shou\ld be disp\layed if the user does not exist?

Part of the Eva\luation process that we ca\l\l Software Testing is about
expanding our mode\l so that we can exp\lore the System more thorough\ly
and provide more information.

We a\lso have to go beyond our mode\l of the requirements and identify Risks
associated with potentia\l imp\lementation, or the techno\logy used, or the
a\lgorithms we have imp\lemented.

For examp\le there might be a risk that the password has been stored in
p\laintext in the database, and an additiona\l risk that the imp\lementation
has coded with a '\like' comparison on the password rather than an 'equa\ls'
so it might be possib\le to use wi\ldcards in the password and \login knowing
on\ly a partia\l password.

This wou\ld a\lso \lead to risks about the security of the app\lication and SQL
Injection.

These might not be covered in the Requirement mode\l, and may not be present
in every Tester's or Programmer's mode\l of the System because they may not
have experience or know\ledge about Security Testing.

At times there is end\less set of possib\le ways we cou\ld expand our mode\l
and how we can exp\lore it in conjunction with the system. And one of the
key ski\l\ls of a Tester is knowing when 'enough is enough' and stopping the
identification and exp\loration of possibi\lities.
  */
  
}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }


  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

  /*
Negative Confirmation is often ca\l\led a 'Test Fai\l'.

This means we observed something we did not expect.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    positive_confirmation;
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=1 height=0];
    negative_confirmation;
  }

  negative_confirmation [
    \labe\l ="Negative\n Confirmation",
    fi\l\lco\lor=red,
    sty\le=fi\l\led
  ]


  /*
These positive and negative reports are a visib\le output
from the Testing process.
  */


  /*
So we have to investigate what fai\led during our comparison process.
  */

  negative_confirmation -> investigation;
  investigation [
    \labe\l="Investigate",
    shape=square
  ]

  /*
This might mean:

- a prob\lem with our mode\l
- a prob\lem with the System Under Test
- a prob\lem with our comparison process

Either way it is something we have to investigate.
  */

  investigation -> mode\l [
    \labe\l="- Mode\l does not \\l  match rea\lity \\l- Change the mode\l.\\l"
  ];

  investigation -> compare [
    \labe\l="- Process Issue.\\l- We did not use\\l  the system proper\ly.\\l- Re-eva\luate.\\l"
    \lhead=c\luster_eva\luation
  ];

  investigation -> raise_bug [
    \labe\l="- System does not match\n what we require."
  ];
  raise_bug [\labe\l="Raise Bug"];
  raise_bug -> fix_bug;
  fix_bug [\labe\l="Fix Bug"];
  fix_bug -> comparison_thing [\labe\l="- Fix the System"];


  subgraph c\luster_investigate {
    investigation;

        subgraph c\luster_defect_process {
          rank=same
          node [rankdir=LR]
          raise_bug;
          fix_bug;
        }
  }

  /*
A comparison process from mode\l to 'thing' isn't the on\ly process that
Software Testing invo\lves, it's just one of the most obvious ways we have
of eva\luating the Software.

And Software Testing is a process of eva\luating the software.

  */
  compare [sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  subgraph c\luster_eva\luation {
      \labe\l="Eva\luation";
      compare;
  }

  /*

We can direct\ly compare Requirements with the Software for high \leve\l surface
positive or negative confirmation that a requirement has been imp\lemented.

e.g. "A User must be ab\le to \login with their username and password." can be
confirmed quite simp\ly by \logging in with an existing user and their correct
password.

But during the Software Testing process we a\lso try to expand our mode\l beyond
Requirements.

We a\lso exp\lore our mode\l in conjunction with the system to \learn more about
our mode\l and as a consequence, the system itse\lf.
  
  */

  compare [sty\le=fi\l\led, fi\l\lco\lor=white];
  subgraph c\luster_eva\luation {
      rank=same
      node [rankdir=LR]
      \labe\l="Eva\luation";
      compare;
      mode\l\ling;
      exp\loration;
  }

  /*

Software Testing has to exp\lore our mode\l to identify:

- risks
- ambiguity
- gaps in the mode\ls and imp\lementation
- etc.

This raises questions which we have to investigate and discuss.

The ongoing process of mode\l\ling is how we generate our ideas
for testing and how we find new ways to exp\lore the software.

  */


  mode\l\ling [\labe\l="Mode\ling", shape=square, sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  mode\l\ling -> mode\l [
    \labe\l="Expand Mode\l:\\l\\l- risks\\l- ambiguity\\l- gaps\\l- questions\\l - etc.\\l"
    \ltai\l=c\luster_eva\luation;
  ];

  /*
The mode\l is both an input to testing, and an output from Testing.

Parts of the mode\l wi\l\l be stored in the Tester's head as a menta\l mode\l.

Other parts wi\l\l be visib\le in the form of diagrams, reports,
\lists of test ideas, etc.
  */
  mode\l [\labe\l="Mode\l" sty\le=fi\l\led fi\l\lco\lor=ye\l\low];

  /*

Software Testing then has to exp\lore the mode\l in conjunction
with the system to identify if any of these manifest as issues
or potentia\l\ly require reworking the imp\lementation.

  */

  mode\l\ling [\labe\l="Mode\ling", shape=square, sty\le=fi\l\led, fi\l\lco\lor=white];
  exp\loration [\labe\l="Exp\loring", shape=square, sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];

  {mode\l comparison_thing} -> compare [\lhead=c\luster_eva\luation];


    /*
One examp\le of ambiguity arises from requirements being natura\l\ly incomp\lete because
of assumptions in understanding.

The requirement for \logging into the system does not describe:

- what happens if the user is a\lready \logged in?
- what message is disp\layed if the user gets the password wrong?
- what message shou\ld be disp\layed if the user does not exist?

Part of the Eva\luation process that we ca\l\l Software Testing is about
expanding our mode\l so that we can exp\lore the System more thorough\ly
and provide more information.

We a\lso have to go beyond our mode\l of the requirements and identify Risks
associated with potentia\l imp\lementation, or the techno\logy used, or the
a\lgorithms we have imp\lemented.

For examp\le there might be a risk that the password has been stored in
p\laintext in the database, and an additiona\l risk that the imp\lementation
has coded with a '\like' comparison on the password rather than an 'equa\ls'
so it might be possib\le to use wi\ldcards in the password and \login knowing
on\ly a partia\l password.

This wou\ld a\lso \lead to risks about the security of the app\lication and SQL
Injection.

These might not be covered in the Requirement mode\l, and may not be present
in every Tester's or Programmer's mode\l of the System because they may not
have experience or know\ledge about Security Testing.

At times there is end\less set of possib\le ways we cou\ld expand our mode\l
and how we can exp\lore it in conjunction with the system. And one of the
key ski\l\ls of a Tester is knowing when 'enough is enough' and stopping the
identification and exp\loration of possibi\lities.
  */
  
  /*
## Exp\loring

The act of exp\loring a mode\l, or using the mode\l as a basis for exp\loring the
system, is the main way that we test softare.

Some of the outputs from this process are captured as part of the mode\l itse\lf.

Other outputs vary depending on the process used but inc\lude artifacts \like:

- execution or exp\loration \logs
- coverage reports
- questions
- decisions
- ideas for new exp\loration approaches
- issues
- issue investigations

  */


    subgraph c\luster_exp\loration_outputs {
      \labe\l="Exp\loration Artifacts";
      rank=same
      node [rankdir=LR]
      // a\l\low it to render without any visib\le nodes
      exp\loration_artifacts [
        \labe\l= "- execution or exp\loration \logs\\l
- coverage reports\\l
- questions\\l
- decisions\\l
- ideas for new exp\loration approaches\\l
- issues\\l
- issue investigations\\l"
    shape=square
      ];
    }

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }


  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

  /*
Negative Confirmation is often ca\l\led a 'Test Fai\l'.

This means we observed something we did not expect.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    positive_confirmation;
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=1 height=0];
    negative_confirmation;
  }

  negative_confirmation [
    \labe\l ="Negative\n Confirmation",
    fi\l\lco\lor=red,
    sty\le=fi\l\led
  ]


  /*
These positive and negative reports are a visib\le output
from the Testing process.
  */


  /*
So we have to investigate what fai\led during our comparison process.
  */

  negative_confirmation -> investigation;
  investigation [
    \labe\l="Investigate",
    shape=square
  ]

  /*
This might mean:

- a prob\lem with our mode\l
- a prob\lem with the System Under Test
- a prob\lem with our comparison process

Either way it is something we have to investigate.
  */

  investigation -> mode\l [
    \labe\l="- Mode\l does not \\l  match rea\lity \\l- Change the mode\l.\\l"
  ];

  investigation -> compare [
    \labe\l="- Process Issue.\\l- We did not use\\l  the system proper\ly.\\l- Re-eva\luate.\\l"
    \lhead=c\luster_eva\luation
  ];

  investigation -> raise_bug [
    \labe\l="- System does not match\n what we require."
  ];
  raise_bug [\labe\l="Raise Bug"];
  raise_bug -> fix_bug;
  fix_bug [\labe\l="Fix Bug"];
  fix_bug -> comparison_thing [\labe\l="- Fix the System"];


  subgraph c\luster_investigate {
    investigation;

        subgraph c\luster_defect_process {
          rank=same
          node [rankdir=LR]
          raise_bug;
          fix_bug;
        }
  }

  /*
A comparison process from mode\l to 'thing' isn't the on\ly process that
Software Testing invo\lves, it's just one of the most obvious ways we have
of eva\luating the Software.

And Software Testing is a process of eva\luating the software.

  */
  compare [sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  subgraph c\luster_eva\luation {
      \labe\l="Eva\luation";
      compare;
  }

  /*

We can direct\ly compare Requirements with the Software for high \leve\l surface
positive or negative confirmation that a requirement has been imp\lemented.

e.g. "A User must be ab\le to \login with their username and password." can be
confirmed quite simp\ly by \logging in with an existing user and their correct
password.

But during the Software Testing process we a\lso try to expand our mode\l beyond
Requirements.

We a\lso exp\lore our mode\l in conjunction with the system to \learn more about
our mode\l and as a consequence, the system itse\lf.
  
  */

  compare [sty\le=fi\l\led, fi\l\lco\lor=white];
  subgraph c\luster_eva\luation {
      rank=same
      node [rankdir=LR]
      \labe\l="Eva\luation";
      compare;
      mode\l\ling;
      exp\loration;
  }

  /*

Software Testing has to exp\lore our mode\l to identify:

- risks
- ambiguity
- gaps in the mode\ls and imp\lementation
- etc.

This raises questions which we have to investigate and discuss.

The ongoing process of mode\l\ling is how we generate our ideas
for testing and how we find new ways to exp\lore the software.

  */


  mode\l\ling [\labe\l="Mode\ling", shape=square, sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  mode\l\ling -> mode\l [
    \labe\l="Expand Mode\l:\\l\\l- risks\\l- ambiguity\\l- gaps\\l- questions\\l - etc.\\l"
    \ltai\l=c\luster_eva\luation;
  ];

  /*
The mode\l is both an input to testing, and an output from Testing.

Parts of the mode\l wi\l\l be stored in the Tester's head as a menta\l mode\l.

Other parts wi\l\l be visib\le in the form of diagrams, reports,
\lists of test ideas, etc.
  */
  mode\l [\labe\l="Mode\l" sty\le=fi\l\led fi\l\lco\lor=ye\l\low];

  /*

Software Testing then has to exp\lore the mode\l in conjunction
with the system to identify if any of these manifest as issues
or potentia\l\ly require reworking the imp\lementation.

  */

  mode\l\ling [\labe\l="Mode\ling", shape=square, sty\le=fi\l\led, fi\l\lco\lor=white];
  exp\loration [\labe\l="Exp\loring", shape=square, sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];

  {mode\l comparison_thing} -> compare [\lhead=c\luster_eva\luation];


    /*
One examp\le of ambiguity arises from requirements being natura\l\ly incomp\lete because
of assumptions in understanding.

The requirement for \logging into the system does not describe:

- what happens if the user is a\lready \logged in?
- what message is disp\layed if the user gets the password wrong?
- what message shou\ld be disp\layed if the user does not exist?

Part of the Eva\luation process that we ca\l\l Software Testing is about
expanding our mode\l so that we can exp\lore the System more thorough\ly
and provide more information.

We a\lso have to go beyond our mode\l of the requirements and identify Risks
associated with potentia\l imp\lementation, or the techno\logy used, or the
a\lgorithms we have imp\lemented.

For examp\le there might be a risk that the password has been stored in
p\laintext in the database, and an additiona\l risk that the imp\lementation
has coded with a '\like' comparison on the password rather than an 'equa\ls'
so it might be possib\le to use wi\ldcards in the password and \login knowing
on\ly a partia\l password.

This wou\ld a\lso \lead to risks about the security of the app\lication and SQL
Injection.

These might not be covered in the Requirement mode\l, and may not be present
in every Tester's or Programmer's mode\l of the System because they may not
have experience or know\ledge about Security Testing.

At times there is end\less set of possib\le ways we cou\ld expand our mode\l
and how we can exp\lore it in conjunction with the system. And one of the
key ski\l\ls of a Tester is knowing when 'enough is enough' and stopping the
identification and exp\loration of possibi\lities.
  */
  
  /*
## Exp\loring

The act of exp\loring a mode\l, or using the mode\l as a basis for exp\loring the
system, is the main way that we test softare.

Some of the outputs from this process are captured as part of the mode\l itse\lf.

Other outputs vary depending on the process used but inc\lude artifacts \like:

- execution or exp\loration \logs
- coverage reports
- questions
- decisions
- ideas for new exp\loration approaches
- issues
- issue investigations

  */


    subgraph c\luster_exp\loration_outputs {
      \labe\l="Exp\loration Artifacts";
      rank=same
      node [rankdir=LR]
      // a\l\low it to render without any visib\le nodes
      exp\loration_artifacts [
        \labe\l= "- execution or exp\loration \logs\\l
- coverage reports\\l
- questions\\l
- decisions\\l
- ideas for new exp\loration approaches\\l
- issues\\l
- issue investigations\\l"
    shape=square
      ];
    }

  exp\loration -> exp\loration_artifacts [\labe\l="Exp\loration" \lhead=c\luster_exp\loration_outputs];

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }


  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

  /*
Negative Confirmation is often ca\l\led a 'Test Fai\l'.

This means we observed something we did not expect.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    positive_confirmation;
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=1 height=0];
    negative_confirmation;
  }

  negative_confirmation [
    \labe\l ="Negative\n Confirmation",
    fi\l\lco\lor=red,
    sty\le=fi\l\led
  ]


  /*
These positive and negative reports are a visib\le output
from the Testing process.
  */


  /*
So we have to investigate what fai\led during our comparison process.
  */

  negative_confirmation -> investigation;
  investigation [
    \labe\l="Investigate",
    shape=square
  ]

  /*
This might mean:

- a prob\lem with our mode\l
- a prob\lem with the System Under Test
- a prob\lem with our comparison process

Either way it is something we have to investigate.
  */

  investigation -> mode\l [
    \labe\l="- Mode\l does not \\l  match rea\lity \\l- Change the mode\l.\\l"
  ];

  investigation -> compare [
    \labe\l="- Process Issue.\\l- We did not use\\l  the system proper\ly.\\l- Re-eva\luate.\\l"
    \lhead=c\luster_eva\luation
  ];

  investigation -> raise_bug [
    \labe\l="- System does not match\n what we require."
  ];
  raise_bug [\labe\l="Raise Bug"];
  raise_bug -> fix_bug;
  fix_bug [\labe\l="Fix Bug"];
  fix_bug -> comparison_thing [\labe\l="- Fix the System"];


  subgraph c\luster_investigate {
    investigation;

        subgraph c\luster_defect_process {
          rank=same
          node [rankdir=LR]
          raise_bug;
          fix_bug;
        }
  }

  /*
A comparison process from mode\l to 'thing' isn't the on\ly process that
Software Testing invo\lves, it's just one of the most obvious ways we have
of eva\luating the Software.

And Software Testing is a process of eva\luating the software.

  */
  compare [sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  subgraph c\luster_eva\luation {
      \labe\l="Eva\luation";
      compare;
  }

  /*

We can direct\ly compare Requirements with the Software for high \leve\l surface
positive or negative confirmation that a requirement has been imp\lemented.

e.g. "A User must be ab\le to \login with their username and password." can be
confirmed quite simp\ly by \logging in with an existing user and their correct
password.

But during the Software Testing process we a\lso try to expand our mode\l beyond
Requirements.

We a\lso exp\lore our mode\l in conjunction with the system to \learn more about
our mode\l and as a consequence, the system itse\lf.
  
  */

  compare [sty\le=fi\l\led, fi\l\lco\lor=white];
  subgraph c\luster_eva\luation {
      rank=same
      node [rankdir=LR]
      \labe\l="Eva\luation";
      compare;
      mode\l\ling;
      exp\loration;
  }

  /*

Software Testing has to exp\lore our mode\l to identify:

- risks
- ambiguity
- gaps in the mode\ls and imp\lementation
- etc.

This raises questions which we have to investigate and discuss.

The ongoing process of mode\l\ling is how we generate our ideas
for testing and how we find new ways to exp\lore the software.

  */


  mode\l\ling [\labe\l="Mode\ling", shape=square, sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  mode\l\ling -> mode\l [
    \labe\l="Expand Mode\l:\\l\\l- risks\\l- ambiguity\\l- gaps\\l- questions\\l - etc.\\l"
    \ltai\l=c\luster_eva\luation;
  ];

  /*
The mode\l is both an input to testing, and an output from Testing.

Parts of the mode\l wi\l\l be stored in the Tester's head as a menta\l mode\l.

Other parts wi\l\l be visib\le in the form of diagrams, reports,
\lists of test ideas, etc.
  */
  mode\l [\labe\l="Mode\l" sty\le=fi\l\led fi\l\lco\lor=ye\l\low];

  /*

Software Testing then has to exp\lore the mode\l in conjunction
with the system to identify if any of these manifest as issues
or potentia\l\ly require reworking the imp\lementation.

  */

  mode\l\ling [\labe\l="Mode\ling", shape=square, sty\le=fi\l\led, fi\l\lco\lor=white];
  exp\loration [\labe\l="Exp\loring", shape=square, sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];

  {mode\l comparison_thing} -> compare [\lhead=c\luster_eva\luation];


    /*
One examp\le of ambiguity arises from requirements being natura\l\ly incomp\lete because
of assumptions in understanding.

The requirement for \logging into the system does not describe:

- what happens if the user is a\lready \logged in?
- what message is disp\layed if the user gets the password wrong?
- what message shou\ld be disp\layed if the user does not exist?

Part of the Eva\luation process that we ca\l\l Software Testing is about
expanding our mode\l so that we can exp\lore the System more thorough\ly
and provide more information.

We a\lso have to go beyond our mode\l of the requirements and identify Risks
associated with potentia\l imp\lementation, or the techno\logy used, or the
a\lgorithms we have imp\lemented.

For examp\le there might be a risk that the password has been stored in
p\laintext in the database, and an additiona\l risk that the imp\lementation
has coded with a '\like' comparison on the password rather than an 'equa\ls'
so it might be possib\le to use wi\ldcards in the password and \login knowing
on\ly a partia\l password.

This wou\ld a\lso \lead to risks about the security of the app\lication and SQL
Injection.

These might not be covered in the Requirement mode\l, and may not be present
in every Tester's or Programmer's mode\l of the System because they may not
have experience or know\ledge about Security Testing.

At times there is end\less set of possib\le ways we cou\ld expand our mode\l
and how we can exp\lore it in conjunction with the system. And one of the
key ski\l\ls of a Tester is knowing when 'enough is enough' and stopping the
identification and exp\loration of possibi\lities.
  */
  
  /*
## Exp\loring

The act of exp\loring a mode\l, or using the mode\l as a basis for exp\loring the
system, is the main way that we test softare.

Some of the outputs from this process are captured as part of the mode\l itse\lf.

Other outputs vary depending on the process used but inc\lude artifacts \like:

- execution or exp\loration \logs
- coverage reports
- questions
- decisions
- ideas for new exp\loration approaches
- issues
- issue investigations

  */


    subgraph c\luster_exp\loration_outputs {
      \labe\l="Exp\loration Artifacts";
      rank=same
      node [rankdir=LR]
      // a\l\low it to render without any visib\le nodes
      exp\loration_artifacts [
        \labe\l= "- execution or exp\loration \logs\\l
- coverage reports\\l
- questions\\l
- decisions\\l
- ideas for new exp\loration approaches\\l
- issues\\l
- issue investigations\\l"
    shape=square
      ];
    }

  exp\loration -> exp\loration_artifacts [\labe\l="Exp\loration" \lhead=c\luster_exp\loration_outputs];

  /*
Exp\loration is usua\l\ly pursued in sma\l\l chunks of time to make it easier to document
and respond to the information gained during the exp\loration to make decisions
about what to test or investigate next.
  */
  exp\loration -> investigation [\labe\l="Investigate\n Findings"];

}




`,
`
digraph TestingBasics {


  # make graph compound because we want to \link to c\lusters
  graph [compound=true];

  # \labe\l text a\lignment: use backs\lash \l to have \left a\ligned new \lines and n for centered new \lines

  rankdir=TB;
  newrank="true";

  #bgco\lor=transparent;
  
  c\lusterrank=\loca\l

  /*

Testing is underpinned by mode\ls.

e.g. requirements, user stories, scenarios, etc.
  
  */
  
  mode\l;
  
  /*
  
We have the 'thing we are comparing with'. Usua\l\ly a System Under Test.

  */

  comparison_thing [\labe\l="System\n Under\n Test"];

  /*

The mode\l and the SUT are inputs to our testing process.

  */
  subgraph c\luster_inputs {
    \labe\l="Inputs to Testing";
    rank=same;
    mode\l;
    comparison_thing;
  }

  /*

The simp\lest way to use a mode\l for testing is to compare
the mode\l with the System Under Test.

  */

  compare [shape=square];
  subgraph c\luster_eva\luation {
      compare;
  }


  /*
This generates output resu\lts from the comparison.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis ];
  }

  compare [shape=square, \labe\l="Comparison"];
  compare -> output [\labe\l="Comparisons" \lhead=c\luster_comparison_outputs];

  /*
Evidentia\l Observation Output can be used for
negative or positive confirmation.
  */
  

  /*
Positive confirmation is often viewed as a 'Test Pass'.
And basica\l\ly means that 'when we did something we observed
that the system behaved the way that we expect'.

NOTE: this does not mean that the system "works", it just means
that at some point in time, given a specific set of input and process
we observed that the system behaaved as we expected.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=0 height=0];
    positive_confirmation;
  }

  positive_confirmation [
    \labe\l="Positive\n Confirmation",
    fi\l\lco\lor=green,
    sty\le=fi\l\led
    ];

  /*
Negative Confirmation is often ca\l\led a 'Test Fai\l'.

This means we observed something we did not expect.
  */

  subgraph c\luster_comparison_outputs {
    \labe\l="Comparison Output";
    rank=same
    node [rankdir=LR]
    positive_confirmation;
    // a\l\low it to render without any visib\le nodes
    output [ \labe\l="" sty\le = invis fixedsize=true width=1 height=0];
    negative_confirmation;
  }

  negative_confirmation [
    \labe\l ="Negative\n Confirmation",
    fi\l\lco\lor=red,
    sty\le=fi\l\led
  ]


  /*
These positive and negative reports are a visib\le output
from the Testing process.
  */


  /*
So we have to investigate what fai\led during our comparison process.
  */

  negative_confirmation -> investigation;
  investigation [
    \labe\l="Investigate",
    shape=square
  ]

  /*
This might mean:

- a prob\lem with our mode\l
- a prob\lem with the System Under Test
- a prob\lem with our comparison process

Either way it is something we have to investigate.
  */

  investigation -> mode\l [
    \labe\l="- Mode\l does not \\l  match rea\lity \\l- Change the mode\l.\\l"
  ];

  investigation -> compare [
    \labe\l="- Process Issue.\\l- We did not use\\l  the system proper\ly.\\l- Re-eva\luate.\\l"
    \lhead=c\luster_eva\luation
  ];

  investigation -> raise_bug [
    \labe\l="- System does not match\n what we require."
  ];
  raise_bug [\labe\l="Raise Bug"];
  raise_bug -> fix_bug;
  fix_bug [\labe\l="Fix Bug"];
  fix_bug -> comparison_thing [\labe\l="- Fix the System"];


  subgraph c\luster_investigate {
    investigation;

        subgraph c\luster_defect_process {
          rank=same
          node [rankdir=LR]
          raise_bug;
          fix_bug;
        }
  }

  /*
A comparison process from mode\l to 'thing' isn't the on\ly process that
Software Testing invo\lves, it's just one of the most obvious ways we have
of eva\luating the Software.

And Software Testing is a process of eva\luating the software.

  */
  compare [sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  subgraph c\luster_eva\luation {
      \labe\l="Eva\luation";
      compare;
  }

  /*

We can direct\ly compare Requirements with the Software for high \leve\l surface
positive or negative confirmation that a requirement has been imp\lemented.

e.g. "A User must be ab\le to \login with their username and password." can be
confirmed quite simp\ly by \logging in with an existing user and their correct
password.

But during the Software Testing process we a\lso try to expand our mode\l beyond
Requirements.

We a\lso exp\lore our mode\l in conjunction with the system to \learn more about
our mode\l and as a consequence, the system itse\lf.
  
  */

  compare [sty\le=fi\l\led, fi\l\lco\lor=white];
  subgraph c\luster_eva\luation {
      rank=same
      node [rankdir=LR]
      \labe\l="Eva\luation";
      compare;
      mode\l\ling;
      exp\loration;
  }

  /*

Software Testing has to exp\lore our mode\l to identify:

- risks
- ambiguity
- gaps in the mode\ls and imp\lementation
- etc.

This raises questions which we have to investigate and discuss.

The ongoing process of mode\l\ling is how we generate our ideas
for testing and how we find new ways to exp\lore the software.

  */


  mode\l\ling [\labe\l="Mode\ling", shape=square, sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];
  mode\l\ling -> mode\l [
    \labe\l="Expand Mode\l:\\l\\l- risks\\l- ambiguity\\l- gaps\\l- questions\\l - etc.\\l"
    \ltai\l=c\luster_eva\luation;
  ];

  /*
The mode\l is both an input to testing, and an output from Testing.

Parts of the mode\l wi\l\l be stored in the Tester's head as a menta\l mode\l.

Other parts wi\l\l be visib\le in the form of diagrams, reports,
\lists of test ideas, etc.
  */
  mode\l [\labe\l="Mode\l" sty\le=fi\l\led fi\l\lco\lor=ye\l\low];

  /*

Software Testing then has to exp\lore the mode\l in conjunction
with the system to identify if any of these manifest as issues
or potentia\l\ly require reworking the imp\lementation.

  */

  mode\l\ling [\labe\l="Mode\ling", shape=square, sty\le=fi\l\led, fi\l\lco\lor=white];
  exp\loration [\labe\l="Exp\loring", shape=square, sty\le=fi\l\led, fi\l\lco\lor=ye\l\low];

  {mode\l comparison_thing} -> compare [\lhead=c\luster_eva\luation];


    /*
One examp\le of ambiguity arises from requirements being natura\l\ly incomp\lete because
of assumptions in understanding.

The requirement for \logging into the system does not describe:

- what happens if the user is a\lready \logged in?
- what message is disp\layed if the user gets the password wrong?
- what message shou\ld be disp\layed if the user does not exist?

Part of the Eva\luation process that we ca\l\l Software Testing is about
expanding our mode\l so that we can exp\lore the System more thorough\ly
and provide more information.

We a\lso have to go beyond our mode\l of the requirements and identify Risks
associated with potentia\l imp\lementation, or the techno\logy used, or the
a\lgorithms we have imp\lemented.

For examp\le there might be a risk that the password has been stored in
p\laintext in the database, and an additiona\l risk that the imp\lementation
has coded with a '\like' comparison on the password rather than an 'equa\ls'
so it might be possib\le to use wi\ldcards in the password and \login knowing
on\ly a partia\l password.

This wou\ld a\lso \lead to risks about the security of the app\lication and SQL
Injection.

These might not be covered in the Requirement mode\l, and may not be present
in every Tester's or Programmer's mode\l of the System because they may not
have experience or know\ledge about Security Testing.

At times there is end\less set of possib\le ways we cou\ld expand our mode\l
and how we can exp\lore it in conjunction with the system. And one of the
key ski\l\ls of a Tester is knowing when 'enough is enough' and stopping the
identification and exp\loration of possibi\lities.
  */
  
  /*
## Exp\loring

The act of exp\loring a mode\l, or using the mode\l as a basis for exp\loring the
system, is the main way that we test softare.

Some of the outputs from this process are captured as part of the mode\l itse\lf.

Other outputs vary depending on the process used but inc\lude artifacts \like:

- execution or exp\loration \logs
- coverage reports
- questions
- decisions
- ideas for new exp\loration approaches
- issues
- issue investigations

  */


    subgraph c\luster_exp\loration_outputs {
      \labe\l="Exp\loration Artifacts";
      rank=same
      node [rankdir=LR]
      // a\l\low it to render without any visib\le nodes
      exp\loration_artifacts [
        \labe\l= "- execution or exp\loration \logs\\l
- coverage reports\\l
- questions\\l
- decisions\\l
- ideas for new exp\loration approaches\\l
- issues\\l
- issue investigations\\l"
    shape=square
      ];
    }

  exp\loration -> exp\loration_artifacts [\labe\l="Exp\loration" \lhead=c\luster_exp\loration_outputs];

  /*
Exp\loration is usua\l\ly pursued in sma\l\l chunks of time to make it easier to document
and respond to the information gained during the exp\loration to make decisions
about what to test or investigate next.
  */
  exp\loration -> investigation [\labe\l="Investigate\n Findings"];

//   # Fin - reset any temporary high\lights
  exp\loration [\labe\l="Exp\loring", shape=square, sty\le=fi\l\led, fi\l\lco\lor=white];
  
}




`,

];

</script>